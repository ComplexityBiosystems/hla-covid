{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import epitopepredict as ep\n",
    "from epitopepredict import base, sequtils, analysis, plotting\n",
    "from mhcflurry import Class1AffinityPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads predictions from the netMHCpan server, applies a filter from netchop and saves data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df1=pd.read_csv(\"../DATA/NetMHCpan-1.csv\",sep=';',skiprows=1)\n",
    "df2=pd.read_csv(\"../DATA/NetMHCpan-2.csv\",sep=';',skiprows=1)\n",
    "df3=pd.read_csv(\"../DATA/NetMHCpan-3.csv\",sep=';',skiprows=1)\n",
    "df4=pd.read_csv(\"../DATA/NetMHCpan-4.csv\",sep='\\t',skiprows=1)\n",
    "df5=pd.read_csv(\"../DATA/NetMHCpan-5.csv\",sep='\\t',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1 contains predictions for: \n",
    "HLA-A01:01,HLA-A02:01,HLA-A02:05,HLA-A03:01,HLA-A11:01,HLA-A23:01,HLA-A24:02,HLA-A24:03,HLA-A25:01,HLA-A26:01,HLA-A29:02,HLA-A30:01,HLA-A30:02,HLA-A31:01,HLA-A32:01,HLA-A33:01,HLA-A66:01,HLA-A68:01,HLA-A68:02,\n",
    "\n",
    "df2 contains predictions for: \n",
    "HLA-A02:17,HLA-B07:02,HLA-B08:01,HLA-B14:02,HLA-B15:01,HLA-B15:17,HLA-B18:01,HLA-B35:01,HLA-B35:03,HLA-B38:01,HLA-B40:02,HLA-B44:02,HLA-B44:03,HLA-B51:01,HLA-B57:01\n",
    "\n",
    "df3 contains predictions for: \n",
    "HLA-B27:05,HLA-B37:01,HLA-B39:01,HLA-B40:01,HLA-B58:01,HLA-C03:03,HLA-C04:01,HLA-C05:01,HLA-C06:02,HLA-C07:02,HLA-C08:02,HLA-C12:03,HLA-C14:02,HLA-C15:02\n",
    "\n",
    "df4 contains predictions for: \n",
    "HLA-A02:02,HLA-A02:03,HLA-A02:06,HLA-A02:07,HLA-A02:11,HLA-A02:12,HLA-A02:16,HLA-A02:19,HLA-A02:50,HLA-A26:02,HLA-A26:03,HLA-A68:23,HLA-A69:01,\n",
    "\n",
    "df5 contains predictions for: \n",
    "HLA-A80:01, HLA-B08:02,HLA-B08:03,HLA-B15:02,HLA-B15:03,HLA-B15:09,HLA-B27:02,HLA-B27:03,HLA-B27:04,HLA-B27:06,HLA-B39:06,HLA-B42:01,HLA-B45:01,HLA-B46:01,HLA-B48:01,HLA-B53:01,HLA-B54:01,HLA-B83:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles=pd.read_csv(\"../DATA/allele-netMHC-2.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_list=list(alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for allele in allele_list:\n",
    "    allele2= allele[:5] + '*' + allele[5:]\n",
    "    newlist.append(allele2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_list=newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbase=df1.drop(df1.iloc[:,3:100], axis=1)\n",
    "dfrest=df1.drop(df1.iloc[:,0:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "imin=0    \n",
    "imax=5\n",
    "dfadd=dfrest.iloc[:,imin:imax]\n",
    "dfadd[\"allele\"]=allele_list[k]\n",
    "dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "df_tot=dfbase.join(dfadd)\n",
    "for i in range(1,19):\n",
    "    imin=i*5\n",
    "    imax=(i+1)*5\n",
    "    dfadd=dfrest.iloc[:,imin:imax]\n",
    "    k=k+1\n",
    "    dfadd[\"allele\"]=allele_list[k]\n",
    "    dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "    dfadd2=dfbase.join(dfadd)\n",
    "    frames = [df_tot, dfadd2]\n",
    "    df_tot=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbase=df2.drop(df2.iloc[:,3:80], axis=1)\n",
    "dfrest=df2.drop(df2.iloc[:,0:3], axis=1)\n",
    "for i in range(0,15):\n",
    "    imin=i*5\n",
    "    imax=(i+1)*5\n",
    "    dfadd=dfrest.iloc[:,imin:imax]\n",
    "    k=k+1\n",
    "    dfadd[\"allele\"]=allele_list[k]\n",
    "    dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "    dfadd2=dfbase.join(dfadd)\n",
    "    frames = [df_tot, dfadd2]\n",
    "    df_tot=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbase=df3.drop(df3.iloc[:,3:75], axis=1)\n",
    "dfrest=df3.drop(df3.iloc[:,0:3], axis=1)\n",
    "for i in range(0,14):\n",
    "    imin=i*5\n",
    "    imax=(i+1)*5\n",
    "    dfadd=dfrest.iloc[:,imin:imax]\n",
    "    k=k+1\n",
    "    dfadd[\"allele\"]=allele_list[k]\n",
    "    dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "    dfadd2=dfbase.join(dfadd)\n",
    "    frames = [df_tot, dfadd2]\n",
    "    df_tot=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbase=df4.drop(df4.iloc[:,3:70], axis=1)\n",
    "dfrest=df4.drop(df4.iloc[:,0:3], axis=1)\n",
    "for i in range(0,13):\n",
    "    imin=i*5\n",
    "    imax=(i+1)*5\n",
    "    dfadd=dfrest.iloc[:,imin:imax]\n",
    "    k=k+1\n",
    "    dfadd[\"allele\"]=allele_list[k]\n",
    "    dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "    dfadd2=dfbase.join(dfadd)\n",
    "    frames = [df_tot, dfadd2]\n",
    "    df_tot=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbase=df5.drop(df5.iloc[:,3:95], axis=1)\n",
    "dfrest=df5.drop(df5.iloc[:,0:3], axis=1)\n",
    "for i in range(0,18):\n",
    "    imin=i*5\n",
    "    imax=(i+1)*5\n",
    "    dfadd=dfrest.iloc[:,imin:imax]\n",
    "    k=k+1\n",
    "    dfadd[\"allele\"]=allele_list[k]\n",
    "    dfadd.columns = ['core','icore','1-log50k','nM','Rank','allele']\n",
    "    dfadd2=dfbase.join(dfadd)\n",
    "    frames = [df_tot, dfadd2]\n",
    "    df_tot=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list from NetChop\n",
    "chop=pd.read_csv(\"../Data/cleavege-Wuhan-4.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter\n",
    "filter=chop[chop[\"C\"]==\"S\"]\n",
    "filter=filter[[\"pos\",\"Ident\"]]\n",
    "filter_key=filter[[\"pos\",\"Ident\"]].apply(tuple, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot['ID']=df_tot['ID'].str[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_tot[[\"Pos\",\"ID\"]].apply(lambda x: tuple(x) in list(filter_key.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filter=df_tot[idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szapperi/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "results_filter[\"K_tot\"]=1./results_filter[\"nM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filter.to_csv(\"df_netMHCpan-all_alleles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
